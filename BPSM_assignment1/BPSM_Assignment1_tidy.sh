### -------------- USEFUL INFO FOR ISH ###  --------------- ### 

#git = https://github.com/IshIshIsh/Learning.git
#To upload from computer to bioinformatics server: 
#C:\Users\milney>scp Desktop\BPSM_assignment1_chart_rounds.vsdx ifarquha@129.215.237.197:/localdisk/home/ifarquha 

#1) copy folder Assignment1 to home space (resets permissions):  
#2) If needing to retest, delete contents of ./BPSM_assignment1 with 
#   cp /localdisk/data/BPSM/Assignment1/* ./BPSM_assignment1/ -r
#   rm -f -r Assignment1


### --------------  A pipeline for the analysis of paired-end RNA-Seq  reads using fastqc, bowtie2, samtools and bedtools   --------------- ###

## Assumptions: 
# raw sequence files are in fq.gz format and stored in one folder
# a mapping file is located within this folder 
# a fasta format genome sequence is provided in the specified genome_dir  


## Global defaults 
working_directory=BPSM_assignment1
fastqc_data_dir="$working_directory/fastq"

# threading is used at an approproiate level for the active computer - please check the defaults before running. 
# TO GET CPU INFO: cat /proc/cpuinfo and select a thread count based on the output (in a power of two to make use of alignmment)
threads=16 

## Bowtie variables 
genome="$working_directory/Tbb_genome"
zipfilename=Tb927_genome.fasta.gz
fasta=Tb927_genome.fasta
genomename=Tb927_genome
mapfile=fqfiles

## Bedtools variables  
bedfile="$working_directory/Tbbgenes.bed"

### -------------- Fastqc Pipeline  --------------- ### 

# As fastqc doesn't create directories we want to create a folder to store the output in if it doesn't already exist:
# check the default folder name (fastqc_output) doesn't exist in working directory and if not, create it.

## TO DO: ADD OFS = "\t" so that we don't need to explicity print tabs in AWK!
### then change 'BEGIN {FS="\t"}; to command line switch as it shouldn't really be inside the awk script. 

# To keep things neat create a directory for the fastqc output in the working directory
if [ ! -d "$working_directory/fastqc_output" ]; then
    mkdir "$working_directory/fastqc_output"
fi 
fastqc_out_dir="$working_directory/fastqc_output"

# for each file in the fastqc_data_dir
# if the file is a fasta file (excluding the map file which has no file extension)
filesforfastqc=''
for file in $(ls "$fastqc_data_dir/"*.fq.gz)
do 
filesforfastqc="$filesforfastqc $file"
# run fastqc on the data and output the results to the fastqc_out_dir
done
fastqc $filesforfastqc -o $fastqc_out_dir -t $threads

### fastqc outputs the data to fastqc_output/filename and creates many files in a zip file and a html file. 
## On extraction of the zip files, mutiple folders and files exist: 
##  fastqc_data.txt  fastqc.fo  fastqc_report.html  Icons  Images  summary.txt
## In summary.txt and pass/warn/fail report is generated with columns (tab seperated) of 'Pass  Test    File'

# extract only the summary.txt file to save space, 
# OPTIONAL pipe outputs of extracted file and re-zip. 
for outfile in $(find "$fastqc_out_dir/"*.zip -type f -printf "%f\n")
do
unzip -p "$fastqc_out_dir/$outfile" *summary.txt >  "$working_directory/fastqc_output/$outfile.txt"
done

# remove any autogenerated files from previous runs
rm -f "$working_directory/fastqc_output/full_summary.txt"
rm -f "$working_directory/fastqc_output/testing_summary.tsv" 

# Collate all the testing information from the zip'd output of fastqc, sort the output to various summary files and print out important info.
pass=0
warn=0
fail=0 
for file in $(find "$working_directory/fastqc_output/"*.txt -type f -printf "%f\n"); 
do 
while IFS=$'\t' read result testtype filename; 
do  
if [ "$result" == "PASS" ]; then
pass=$((pass+1)) 
fi; 
if [ "$result" == "WARN" ]; then
warn=$((warn+1))
fi; 
if [ "$result" == "FAIL" ]; then
fail=$((fail+1))
fi; 
echo -e "$filename\t$testtype\t$result" >> "$working_directory/fastqc_output/full_summary.txt"
done < "$working_directory/fastqc_output/$file"
done
total=$((pass+warn+fail))
echo "Pass: $pass/$total"
if [ $warn != 0 ] || [ $fail != 0 ]; then 
echo "WARNING: failed tests: $fail/$total, warnings: $warn/$total"

# print the number of files which failed or passed each test and write the filenames to a file in the format 'test', 'error', 'filelist'
# this would allow (if a very important test failed, to pull out an array of those filenames to filter your data for further analysis)
awk 'BEGIN {FS="\t"}; {if($3 == "FAIL") failedtest[$2]++} END {for (k in failedtest) print k, "\t", failedtest[k] }' "$working_directory/fastqc_output/full_summary.txt" 
awk 'BEGIN {FS="\t"}; {if($3 == "WARN") warntest[$2]++} END {for (k in warntest) print k, "\t", warntest[k] }'  "$working_directory/fastqc_output/full_summary.txt" 

# Create a text file which contains arrays of failed reads for each testing (so if you wanted to exclude any that failed an important test you could easily pull out this information)
awk 'BEGIN {FS="\t"}; {if($3 == "FAIL") failedtest[$2]++} {filenames=$1 "," filenames} END {for (k in failedtest) print k, "\t", "FAIL", "\t", filenames }' "$working_directory/fastqc_output/full_summary.txt"  >> "$working_directory/fastqc_output/testing_summary.tsv" 
awk 'BEGIN {FS="\t"}; {if($3 == "WARN") warntest[$2]++} {filenames=$1 "," filenames} END {for (k in warntest) print k, "\t", "WARN" , "\t", filenames}'  "$working_directory/fastqc_output/full_summary.txt"  >> "$working_directory/fastqc_output/testing_summary.tsv"
fi;

# Create a table format testing summary output (for easily identifying problem reads)
awk 'BEGIN {FS="\t"}; {tests[$2]++}END{printf "file\t"; for (t in tests) {printf "%s ",t;printf "\t"}print "";}' "$working_directory/fastqc_output/full_summary.txt" >  "$working_directory/fastqc_output/table_summary.tsv"
awk 'BEGIN {FS="\t"}; {results[$1][$2]=$3} END {for (file in results){ printf file; printf "\t"; for (test in results[file]){ printf results[file][test];printf "\t";}print "";}}' "$working_directory/fastqc_output/full_summary.txt" >> "$working_directory/fastqc_output/table_summary.tsv" 


# OPTIONAL: Look into using MultiQC after FastQC but this may be cheating as not specified in assignment
# QUESTION: How can you look at the html or png files? 
# QUESTION: Do we read in files paired, in groups or one by one 

### -------------- Bowtie Pipeline --------------- ### 

# To keep analysis neat create a folder called bowtie in the working_directory
if [ ! -d "$working_directory/bowtie" ]; then
    mkdir "$working_directory/bowtie"
fi 
genomeseq="$working_directory/bowtie"


## Unzip the files in the reference genome
# OPTIONAL: Fina a way to pipe into -build so that we don't take up extra space? 
gunzip "$genome/$zipfilename" 

## Create a Bowtie2 index genome from the fasta files from the reference genome
bowtie2-build "$genome/$fasta" "$working_directory/bowtie/$genomename"


### NOTE some fields in fqfiles are tab seperated and others are not: use cat -T to check tab locations then correct for this: 
unexpand -a "$fastqc_data_dir/$mapfile" > "$fastqc_data_dir/$mapfile"_corrected

stumpy1s=$(awk -v dir_prefix="$fastqc_data_dir/" 'BEGIN {FS="\t"}; { if($2~/.*Stumpy.*/) filenames=dir_prefix $3 "," filenames}  END {print filenames}' "$fastqc_data_dir/$mapfile"_corrected)
stumpy2s=$(awk -v dir_prefix="$fastqc_data_dir/" 'BEGIN {FS="\t"}; {if($2~/.*Stumpy.*/) filenames=dir_prefix $4 "," filenames}  END {print filenames}' "$fastqc_data_dir/$mapfile"_corrected)
slender1s=$(awk -v dir_prefix="$fastqc_data_dir/" 'BEGIN {FS="\t"}; {if($2~/.*Slender.*/) filenames=dir_prefix $3 "," filenames}  END {print filenames}' "$fastqc_data_dir/$mapfile"_corrected)
slender2s=$(awk -v dir_prefix="$fastqc_data_dir/" 'BEGIN {FS="\t"}; {if($2~/.*Slender.*/) filenames=dir_prefix $4 "," filenames}  END {print filenames}' "$fastqc_data_dir/$mapfile"_corrected)

# Bowtie will produce a huge 16gb file (which is too huge!) so pipe directly to samtools instead (you can use -bSF4 to exclude any unmapped reads) and set threading with -@
# -x is the index file, -p is the number of threads (preset globally), --mm is using memory mapping index 
bowtie2 -x "$working_directory/bowtie/$genomename" -p $threads --mm -1 $stumpy1s -2 $stumpy2s  | samtools view -bS - > "$working_directory/bowtie/$genomename"_stumpy.bam -@ $threads
bowtie2 -x "$working_directory/bowtie/$genomename" -p $threads --mm -1 $slender1s -2 $slender2s| samtools view -bS - > "$working_directory/bowtie/$genomename"_slender.bam -@ $threads

## sort the bam files with threading
samtools sort "$working_directory/bowtie/$genomename"_stumpy.bam -o "$working_directory/bowtie/$genomename"_stumpy_sorted.bam -@ $threads
samtools sort "$working_directory/bowtie/$genomename"_slender.bam -o "$working_directory/bowtie/$genomename"_slender_sorted.bam -@ $threads


## index the bam files with threading 
samtools index "$working_directory/bowtie/$genomename"_stumpy_sorted.bam -@ $threads
samtools index "$working_directory/bowtie/$genomename"_slender_sorted.bam -@ $threads


### -------------- Bedtools and Counts Data Pipeline --------------- ### 

# Pass the slender and stumpy output in indexed bam files to bedtools multicoverage to work out the counts of reads aligned to genes described in the bedfile. 
bedtools multicov -bams "$working_directory/bowtie/$genomename"_stumpy_sorted.bam "$working_directory/bowtie/$genomename"_slender_sorted.bam -bed $bedfile > "$working_directory/bowtie/$genomename"_hits.txt  

## outputs in the format: 
## original line from the -bed file followed by the count of the alignments that overlap. (1 new column for each bedfile)
## column4 = gene name, column7 = stumpy, column8 = slender
# so we want to get all rows with column4 string and count the number of reads aligned for each stage (stumpy/slender) divided by the total number of reads mapped by that group
## Requested output as
## gene_name    mean_slender    mean_stumpy
echo -e "gene_name" "\t" "mean_slender" "\t" "mean_stumpy" > "$working_directory/bowtie/$genomename"_filteredhits.txt 
awk 'BEGIN {FS="\t"}; {if($7!=0 || $8!=0) print $4, "\t",$7, "\t",$8}' "$working_directory/bowtie/$genomename"_hits.txt >> "$working_directory/bowtie/$genomename"_filteredhits.txt 



